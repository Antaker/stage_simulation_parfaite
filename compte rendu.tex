
\documentclass[a4paper,oneside,11pt]{article}



%% Language %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[french]{babel} %francais, polish, spanish, ...
\usepackage[T1]{fontenc}
\usepackage[ansinew]{inputenc}
\usepackage{lmodern} %Type1-font for non-english texts and characters
\usepackage{xcolor}
\usepackage{amsmath,amsfonts,amssymb}


%% Packages for Graphics & Figures %%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx} %%For loading graphic files


%% Math Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\newtheorem{definition}{Définition}
\newtheorem{theorem}{Th\'eor\`eme}
\newtheorem{lemme}{Lemme}

%%inclusion de code et pseudo-code%%
\usepackage{listings} %%permet l'insertion de code dans le texte%%
\usepackage{algorithm}
\usepackage{algorithmic} 

\makeatletter
\renewcommand{\fnum@algorithm}{\fname@algorithm}
\makeatother


\lstset{
language=R,
basicstyle=\ttfamily\small, %
identifierstyle=\color{red}, %
keywordstyle=\color{blue}, %
stringstyle=\color{black!60}, %
columns=flexible, %
tabsize=2, %
extendedchars=true, %
showspaces=false, %
showstringspaces=false, %
numbers=left, %
numberstyle=\tiny, %
breaklines=true, %
breakautoindent=true, %
captionpos=b, %
rulecolor=\color{black}
}



\begin{document}


\pagestyle{empty} %No headings for the first pages.



\title{Compte rendu stage \\
Simulation parfaite}
\author{Antonin LAURENT}
%\date{} %%If commented, the current date is used.
\maketitle

\newpage

%% Inhaltsverzeichnis %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents %Table of contents

\pagestyle{plain} %Now display headings: headings / fancy / ...

\newpage



\section{Chapitre 1 : Introduction}

\subsection{Définitions et théorèmes}

\begin{definition}
Temps d'arrêt
\end{definition}

On dit que $T$ est un temps d'arrêt pour une suite $X_{1},X_{2},\ldots$ si, connaissant les valeurs de $X_{1},X_{2},\ldots,X_{n}$ on peut déterminer si $T \leq n$.

\begin{definition} 
Fonction calculable
\end{definition}

Une fonction est dite calculable (computable en anglais) si il existe un algorithme capable de retourner le résultat de la fonction.

\begin{definition}
Algorithme probabiliste
\end{definition}

Soient 	$\cal{I}$ un ensemble d'indices tel que pour tout $I \in \cal{I}$, il existe une distribution $\pi_{I}$ sur un espace d'états $\Omega_{I}$. On se donne une suite de variables aléatoires $X_{1},X_{2},\ldots$ où les $X_{I} \in S_{I}$ .\\
Un algorithme probabiliste est une famille de temps d'arrêts $ \left\{ T_{I} \right\}_{I \in \cal{I}}$ et et de fonctions calculables 
$ \left\{ f_{I,t} \right\} _{i \in \mathcal{I}, t \in \left\{ 1,2,\ldots \right\} } $. La sortie de l'algorithme est $f_{I,T_{I}}(X_{1},\ldots,X_{T_{I}})$.\\

\begin{definition}
Algorithme de simulation parfaite
\end{definition}

Un algorithme de simulation parfaite est un algorithme probabiliste dont la sortie est une variable aléatoire qui provient d'une distribution cible.\\
Les algorithmes de simulation parfaite sont une sous-classe des algorithmes de simulation exacte, algorithmes qui tirent d'une distribution ciblée. \\
Cependant les algorithmes dont le temps d'arrêt 
$T_{I}$ est déterministe (algorithmes tournant selon un nombre fini de choix aléatoires) sont généralement considérés comme algorithmes de simulation exacte mais pas comme algorithmes de simulation parfaite.


\begin{theorem}
Théorème fondamental de la simulation parfaite
\end{theorem}

On suppose que pour $U_{1},U_{2},\ldots$ iid tel que $U_{i} \sim$ Unif([0,1]) , il existe des fonctions calculables $b,g$ et $f$ telles que la fonction $b$ aie pour image $ \left\{ 0,1 \right\} $ et $\mathbb{P}(b(U) = 1) > 0$. \\
Pour une variable aléatoire X qui vérifie : 

\begin{equation}
 X \sim b(U)g(U) + (1 - b(U))f(X,U),
 \label{eq1}
\end{equation}




soit $T =$ inf$\left\{t : b(U_{t}) = 1\right\}$. On a alors que :

$$ Y = f(\ldots f(f(g(U_{T}),U_{T-1}),U_{T-2}),\ldots,U_{1})$$

a la même distribution que $X$ et on a $\mathbb{E}[T] = \frac{1}{\mathbb{P}(b(U) = 1)}$.\\
~\\
\begin{proof}
Soient $X_{0},X_{1},\ldots$ des tirages indépendants chacun distribués selon $X$, et $U_{1},U_{2},\ldots$ iid tel que $U_{i} \sim$ Unif([0,1]). Pour $X_{t}$, fixons $X_{t,t} = X_{t}$ et récursivement, on pose :

$$ X_{t,i} = b(U_{i+1})g(U_{i+1}) + (1 - b(U_{i+1}))f(X_{t,i+1},U_{i+1}),  $$
pour $i \in \left\{0,\ldots,t-1\right\}$.\\

On a alors d'après la relation \eqref{eq1} : $X_{t,0} \sim X$. On montre ce résultat pour les premiers indices t, les suivants sont prouvés de la même manière.
\paragraph{\underline{t=0}}

\begin{align*}
X_{0,0} = X_{0} \\
\intertext{comme on l'a posé précédemment, d'où} 
X_{0,0} \sim X.
\end{align*}

\paragraph{\underline{t=1}}

\begin{align*}
X_{1,0} = b(U_{1})g(U_{1}) + (1 - b(U_{1}))f(X_{1,1},U_{1})\\ 
\end{align*}

Or, 

\begin{align*}
X_{1,1} = X_{1} \sim X.\\
\end{align*}

En remplaçant dans l'équation précédente, on obtient :

\begin{align*}
X_{1,0} = b(U_{1})g(U_{1}) + (1 - b(U_{1}))f(X_{1},U_{1})\\ 
\end{align*}
\qquad D'après la relation \eqref{eq1}, on obtient alors $X_{1,0} = X_{1} \sim X$.\\

\paragraph{\underline{t=2}}

\begin{align*}
X_{2,0} &= b(U_{1})g(U_{1}) + (1 - b(U_{1}))f(X_{2,1},U_{1})\\ 
X_{2,1} &= b(U_{2})g(U_{2}) + (1 - b(U_{2}))f(X_{2,2},U_{2})\\
&= b(U_{2})g(U_{2}) + (1 - b(U_{2}))f(X_{2},U_{2})\\
\end{align*}
À nouveau, par la relation \eqref{eq1}, on a : $X_{2,1} = X_{2}$
On remplace donc par cette valeur dans $X_{2,0}$ et on obtient :

\begin{align*}
X_{2,0} &= b(U_{1})g(U_{1}) + (1 - b(U_{1}))f(X_{2},U_{1})\\
\end{align*}

D'après la relation \eqref{eq1}, on obtient alors $X_{2,0} = X_{2} \sim X$.\\

On a donc $X_{0,0},X_{1,0},X_{2,0},\ldots$ de même distribution que $X$ mais pas forcément indépendants. On considère à présent la variable $Y$ énoncée dans le théorème. On a alors la relation suivante : $X_{t,0} = Y$ si $t \geq T$. On illustre ce résultat avec comme exemple $T=2$ et $t=2,3$ : \\
On a donc : 
$$ Y = f(g(U_{2}),U_{1}) $$

Montrons que $X_{2,0} = X_{3,0} = Y$. Étant donné que $T=2$, on a $b(U_{1}) = 0$ et $b(U_{2}) = 1$ , d'où :

\begin{align*}
X_{2,0} &= f(X_{2,1},U_{1})\\
X_{2,1} &= g(U_{2})\\
\intertext{on remplace dans la première équation et on obtient}
X_{2,0} &= f(g(U_{2}),U_{1})\\
\end{align*}

D'où le résultat pour t=2. Voyons pour t=3.\\
~\\
De même, puisque $T=2$, on a $b(U_{1}) = 0$ et $b(U_{2}) = 1$ , d'où :

\begin{align*}
X_{3,0} &= f(X_{3,1},U_{1})\\
X_{3,1} &= g(U_{2})\\
\intertext{on remplace dans la première équation et on obtient}
X_{3,0} &= f(g(U_{2}),U_{1})\\
\end{align*}

D'où le résultat.\\
Ensuite, puisque les $U_{i}$ sont indépendants, on a que : $\mathbb{P}(T > t) = (1 - \mathbb{P}(b(U) = 1))^{t}$ et puisque, par hypothèse, $\mathbb{P}(b(U) = 1) >0$, on a la relation qui tend vers $0$ pour $t$ tendant vers l'infini.
Il ne reste plus qu'à montrer $Y \sim X$. Pour tout $t$, pour tout ensemble $C$ :

\begin{align*}
\mathbb{P}(Y \in C) &= \mathbb{P}(Y \in C, t \geq T) + \mathbb{P}(Y \in C, t < T)
\intertext{puisque $X_{t,0} = Y$ si $t \geq T$, on a}
&= \mathbb{P}(X_{t,0} \in C, t \geq T) + \mathbb{P}(Y \in C, t < T)\\
&= \mathbb{P}(X_{t,0} \in C) - \mathbb{P}(X_{t,0} \in C, t < T) + \mathbb{P}(Y \in C, t < T)
\intertext{puisque $X_{t,0} \sim X$, on a}
&= \mathbb{P}(X \in C) - \mathbb{P}(X_{t,0} \in C, t < T) + \mathbb{P}(Y \in C, t < T)
\end{align*}

Les deux derniers termes sont bornés par $\mathbb{P}(T > t) = (1 - \mathbb{P}(b(U) = 1))^{t}$, et puisque l'équation est vraie pour n'importe quel $t$,  on obtient : $\mathbb{P}(Y \in C) = \mathbb{P}(X \in C)$ pour tout ensemble $C$ , donc $Y \sim X$.
Le fait que $\mathbb{E}[T] = \frac{1}{\mathbb{P}(b(U)=1)}$ provient du fait que $T$ suit une loi géométrique de paramètre $\mathbb{P}(b(U) =1)$

\end{proof}




\begin{definition}
Algorithme arretable
\end{definition}
Dans le théorème fondamental de la simulation parfaite, si $X$ et $T$ sont indépendants, on dit que l'algorithme est arretable, sinon il est non-arretable.

\begin{definition}
Algortihme de simulation parfaite à lecture unique
\end{definition}
Un algorithme de simulation parfaite qui utilise $X \sim b(U)g(U) + (1 - b(U))f(X,U)$ est un algorithme à lecture unique si $f(X,u) = f(X,u')$ pour tout $u$,$u'$. Sinon, c'est un algorithme à lecture double.\\
~\\
En général, un algorithme arretable est préférable à un algorithme non-arretable, et un algorithme à lecture unique est préférable à un algorithme à lecture double.\\

\subsection{Modèles étudiés}

\subsubsection{Champs aléatoires de Markov}

On considère un graphe $G = (V,E)$. $V$ est l'ensemble des n\oe{}uds et $E$ est l'ensemble des arêtes. On notera par la suite $\Delta$ le degré du graphe (égal au degré du n\oe{}ud ayant un nombre de voisins maximal). On notera par $\Omega$ l'ensemble des labels des n\oe{}uds.

\begin{definition}
Ensemble séparant
\end{definition}
On dit qu'un sous-ensemble de n\oe{}uds $S$ sépare les n\oe{}uds $i$ et $j$ si tout chemin du graphe menant $i$ à $j$ passe par $S$.

\begin{definition}
Champ aléatoire de Markov
\end{definition}
Pour un graphe $G = (V,E)$ et un ensemble de labels $\Omega$, on dit que la distribution de $X$ sur $\Omega$ est un champ aléatoire de Markov si, pour tous les n\oe{}uds $i$ et $j$, pour tous les ensembles $S$ séparant $i$ de $j$, on a : $[X(i)|X(j),X(S)] \sim [X(i)|X(S)]$. Un état $x \in \Omega$ est appelé une configuration.

\begin{definition}
Clique
\end{definition}
Une clique est un sous-ensemble de n\oe{}uds du graphe tel que chaque paire de n\oe{}uds soit connectée par une arête.


\begin{theorem}
Théorème de Hammersley Clifford
\end{theorem}
Pour un graphe fini $G=(V,E)$, la distribution $\pi$ est un champ aléatoire de Markov si elle a pour densité $f_{X}$ et qu'il existe des fonctions $\phi _{C}$ pour toute clique C telles que $f_{X}$ puisse s'écrire : 

$$ f_{X}(x) = \frac{1}{Z} \prod _{C \in cliques(G)} \phi_{C}(x)$$


\begin{definition}
Auto-modèle
\end{definition}
On dit qu'un champ aléatoire de Markov est un auto-modèle, si il existe des fonctions $f_{i}$ et $g_{i}$ telles que la densité de $X \sim \pi$ peut-être écrite sous la forme : 
$$ f_{X}(x) = \frac{1}{Z} \left[\prod_{i \in V} f_{i}(X(i))\right]\left[ \prod _{ \left\{i,j \right\} \in E} g_{\left\{i,j\right\}}(X(i),X(j))\right]$$

Dans la suite, on définit des exemples bien connus d'auto-modèles que l'on étudiera par la suite.

\paragraph{Exemple 1 : Modèle d'Ising}
~\\
~\\
Le modèle d'Ising est un auto-modèle de paramètres $\mu$ et $\beta$ , où $\Omega = \left\{ -1,1 \right\} ^{V}$, et $f(c) = exp(\mu c)$, $g(c_{1},c_{2}) = exp(\beta \mathbf{1}(c_{1} = c_{2}))$. Dans la littérature, on appelle $\mu$ magnétisation et $\beta$ la température inverse. Lorsque $\beta >0$, on dit que le modèle est ferromagnétique. Lorsque $\mu = 0$, on dit que le modèle est sans champ magnétique.

\paragraph{Exemple 2 : Modèle Hard-core gas}
~\\
~\\ 
Le modèle hard-core gas est un auto-modèle défini sur $\left\{0,1 \right\} ^{V}$ et de paramètre $\lambda >0$ où $f(c) = \lambda ^{c}$ 
et $g(c_{1},c_{2}) = 1 - c_{1}c_{2}$. Lorsqu'un no\oe{}ud $\nu$ a pour label $1$, on dit que le n\oe{}ud est occupé, sinon, il est inoccupé.

\paragraph{Exemple 3 : Modèle de Strauss}
~\\
~\\
Le modèle de Strauss est un auto-modèle sur $\left\{0,1 \right\} ^{V}$ de paramètres $\lambda >0$ et $\gamma \in [0,1]$ où $f(c) = \lambda ^{c}$ et $g(c_{1},c_{2}) = 1 + (\gamma - 1)c_{1}c_{2}$.Lorsqu'un no\oe{}ud $\nu$ a pour label $1$, on dit que le n\oe{}ud est occupé, sinon, il est inoccupé.

\subsubsection{Permutations}

Un problème classique de distribution sur les permutations est lié à la recherche du permanent d'une matrice non-négative.

\paragraph{Exemple}
~\\
~\\
Pour une matrice non-négative $w(i,j)$, notons :

$$w(\sigma) = \prod_{i=1}^{n} w(i,\sigma(i))$$
\\
\nolinebreak Tant qu'il existe au moins une permutation $\sigma$ telle que $w(i,\sigma(i)) >0$ pour tout $i$, cela donne une densité non normalisée sur l'ensemble des permutations. La constante de normalisation pour cette densité est alors appelée le permanent de la matrice $w(i,j)$. Si aucun $\sigma$ ne vérifie cette relation, le permanent est 0.
~\\
Une autre distribution importante que l'on va considérer est la distribution uniforme sur les permutations où certains objets doivent avoir une position plus faible que les autres.

\begin{definition}
Relation d'ordre partiel
\end{definition}
Soit un ensemble $P$. Une relation d'ordre partiel sur $P$ est une relation binaire $\preceq$ telle que pour tout $a,b,c \in P$, la relation est:

\begin{enumerate}
\item (Réflexive) $a \preceq a$
\item (Antisymétrique) Si $a \preceq b$ et $b \preceq a$, alors $a = b$
\item (Transitive) Si $a \preceq b$ et $b \preceq c$, alors $a \preceq c$
\end{enumerate}

Un ensemble disposant d'une relation d'ordre partiel est parfois appelé poset d'après l'anglais partially ordered set.

\begin{definition}
Extension linéaire d'un ordre partiel
\end{definition}

Une extension linéaire d'un ordre partiel sur $1,\ldots,n$ est une permutation pour laquelle si $i$ et $j$ sont tels que $\sigma(i) \prec \sigma(j)$, alors $i<j$.  

\subsection{Chaînes de Markov et simulation approchée}

Jusqu'au développement des algorithmes de simulation parfaite/exacte, la manière principale d'obtenir une réalisation d'une distribution ciblée était une méthode d'approche. Plusieurs algorithmes et méthodes ont été mis en place et l'ensemble de ces méthodes porte le nom de Chaîne de Markov Monte Carlo (Markov Chain Monte Carlo, MCMC dans la littérature).
~\\
On ne rappellera pas ici les principales définitions pour les chaînes de Markov mais d'autres seront nécessaires pour la suite.
On s'intéressera notamment aux chaînes de Harris et au théorème ergodique associé.

\begin{definition}
Chaîne de Harris
\end{definition}

Une chaîne de Markov $\left\{X_{t} \right\}$ sur un espace d'état $\Omega$ est une chaîne de Harris si il existe des ensembles mesurables $A,B \in \Omega$ et $\epsilon > 0$ pour $x \in A$ et $y \in B$, et une mesure de probabilité $\rho$ où $\rho(B) = 1$ tels que l'on ait :

\begin{enumerate}
\item Pour $T_{A} = inf\left\{ t \geq 0 : X_{t} \in A \right\}, ( \forall z \in \Omega)(\mathbb{P}(T_{A} < \infty | X_{0} = z) > 0).$
\item Si $x \in A$ et $C \subseteq B$, alors $\mathbb{P}(X_{1} \in C | X_{0} = x) \geq \epsilon \rho (C)$
\end{enumerate}  

\begin{definition}
Chaîne récurrente
\end{definition}

Soit $R = inf \left\{ n>0 : X_{n} \in A \right\}$. On dit qu'une chaîne de Harris est une chaîne récurrente si pour tout $x \in A$, $\mathbb{P}(R < \infty | X_{0} = x) = 1$. Une chaîne qui n'est pas récurrente est dite transiente.

\begin{definition}
Chaîne apériodique
\end{definition}

Une chaîne de Harris récurrente est apériodique si pour tout $x \in \Omega$, il existe $n$ tel que pour tout $n' \geq n$, $\mathbb{P}(X_{n'} \in A | X_{0} = x) >0$

\begin{theorem}
Théorème ergodique pour les chaînes de Harris
\end{theorem} 

Soit $X_{n}$ une chaîne de Harris récurrente et apériodique de distribution stationnaire $\pi$. Si $\mathbb{P}(R < \infty | X_{0} = x) = 1$ pour tout $x$, alors, pour $t \to \infty$, pour tout ensemble mesurable $C$ et pour tout $x$ : 

$$ |\mathbb{P}(X_{t} \in C|X_{0} = x) - \pi(C)| \to 0 $$

~\\
Ce théorème est le c\oe{}ur des méthodes MCMC, puisqu'il "suffit" de construire une chaîne de Harris ayant pour distribution stationnaire la distribution souhaitée et de la faire tourner pendant un nombre infini de pas. Cependant, n'ayant pas un temps infini, les utilisateurs font tourner leurs algorithmes durant un grand nombre de pas et espèrent arriver dans la distribution stationnaire.
~\\
\linebreak Nous pourrons cependant déterminer à quel point la chaîne est proche de la loi stationnaire à l'aide du concept de couplage (voir chapitre 3 pour une définition et application étendue).

\begin{definition}
Couplage
\end{definition}
Supposons que $\left\{X_{t} \right\} \sim \nu_{X}$ et $\left\{Y_{t} \right\} \sim \nu_{Y}$. Un couplage de $\left\{X_{t} \right\}$ et $\left\{Y_{t} \right\}$ est un processus bivarié $\left\{(X^{'}_{t},Y^{'}_{t})\right\}$ tel que $\left\{X^{'}_{t} \right\} \sim \nu_{X}$ et $\left\{Y^{'}_{t} \right\} \sim \nu_{Y}$.

\begin{theorem}
Lemme de Couplage
\end{theorem} 

Soit $Y_{0} \sim \pi$ et $X_{0} = x_{0}$ tels que les deux variables évoluent de manière couplée. Alors, pour tout mesurable $C$ :
$$ |\mathbb{P}(X_{t} \in C|X_{0}=x) - \pi(C)| \leq \mathbb{P}(X_{t} \ne Y_{t}).$$

\subsection{Création de chaînes de Markov}

Afin d'utiliser les méthodes MCMC, il faut créer des chaînes de Harris qui convergent vers la distribution $\pi$ ciblée.
Il est généralement mieux de créer des chaînes réversibles plutôt que des chaînes simplement stationnaires.\\
Nous utiliserons la notation suivante pour la définition de réversibilité : $\pi(dx) = f(x)dx$. Et donc, pour tout mesurable $A$, $\pi(A) = \int_{x \in A} \pi(dx) = \int_{x \in A} f(x)dx$.\\
Nous utiliserons l'équation de balance détaillée pour en déduire la réversibilité: 
\begin{definition}
Équation de balance détaillée
\end{definition}

Une distribution $\pi$ est réversible selon une chaîne de Markov $\left\{ X_{t} \right\}$ en particulier si : $\pi(dx)\mathbb{P}(X_{t+1} \in dy | X_{t} = x) = \pi(dy)\mathbb{P}(X_{t+1} \in dx | X_{t} = y).$
\begin{lemme}
\end{lemme}
Si $\pi$ est réversible, alors $\pi$ est stationnaire.
\begin{proof}
Soit $\Omega$ l'espace d'état de la chaîne de Markov $\left\{ X_{t} \right\}$ considérée et $\pi$ réversible pour cette chaîne.
Pour $X_{t} \sim \pi$, et $C$ un ensemble mesurable, alors on a :

\begin{align*}
\mathbb{P}(X_{t+1} \in C) &= \mathbb{E}[\mathbf{1}(X_{t+1} \in C)] \\ 
&= \mathbb{E}[\mathbb{E}[\mathbf{1}(X_{t+1} \in C)|X_{t}]]
\\
&= \int_{x \in \Omega} \mathbb{E}[\mathbf{1}(X_{t+1} \in C)|X_{t} = x]\pi(dx)
\\
&= \int_{x \in \Omega} \mathbb{P}(X_{t+1} \in C | X_{t} = x)\pi(dx)
\\
&= \int_{x \in \Omega} \int_{y \in C} \mathbb{P}(X_{t+1} \in dy|X_{t} = x)\pi(dx)
\\
&= \int_{y \in C} \int_{x \in \Omega} \mathbb{P}(X_{t+1} \in dx|X_{t} = y)\pi(dy)
\\
&=  \int_{y \in C} \mathbb{P}(X_{t+1} \in \Omega|X_{t} = y)\pi(dy)
\\
&= \int_{y \in C} \pi(dy)
\\
&= \pi(C)
\end{align*}

D'où la stationnarité de $\pi$.\\

\end{proof}

Plusieurs types de chaînes réversibles existent telles que l'échantillonnage de Gibbs (Gibbs sampler), Metropolis-Hastings,etc.
\\
Ces chaînes sont présentées dans la suite.

\subsubsection{Échantillonnage de Gibbs}

On présente ici un échantillonneur de Gibbs, qui agit sur un espace d'états de la forme $C^{V}$. On appelle $\nu \in V$ une dimension du problème. Pour $X_{t} = x$, l'échantillonneur choisit une dimension $\nu$ uniformément sur $V$. Soit $L(x,\nu)$ l'ensemble des états qui sont exactement les n\oe{}uds de la configuration $x$ sauf en $\nu$, écrit de la manière suivante : $L(x,v) = \left\{ y : (\forall w \in V \setminus \left\{v\right\})(y(w) = x(w))\right\}.$ Pour $X_{t} = x$, l'état suivant $X_{t+1}$ est choisi selon $\pi$ à conditionné à être dans $L(x,v)$.
\\
On présente comme exemple le modèle d'Ising précédemment vu. Une dimension est alors un n\oe{}ud de la configuration.
On choisit donc un n\oe{}ud uniformément dans $V$, et on considère les états qui sont exactement $x$ en tous les autres n\oe{}uds autres que $\nu$. Pour le modèle d'Ising, la valeur en $\nu$ de x  est $1$ ou $-1$. On note ces configurations $x_{\nu \to 1}$ et $x_{\nu \to -1}$. On choisit alors l'état suivant entre $x_{\nu \to 1}$ et $x_{\nu \to -1}$, où le choix est fait proportionnellement à $\pi$. On a donc : 

$$\mathbb{P}(X_{t+1} = x_{\nu \to 1})  = \frac{\pi(\left\{x_{\nu \to 1}\right\})}{\pi(\left\{x_{\nu \to 1}\right\})+\pi(\left\{x_{\nu \to -1}\right\})}$$

Or, pour le modèle d'Ising,

$$\pi(\left\{x\right\})= \frac{1}{Z}\prod_{i \in V} exp(\mu X(i)) \prod_{\left\{i,j\right\} \in E} exp(\beta \mathbf{1}(x(i)=x(j)).$$

Après simplification, on obtient :
\begin{align*}
\mathbb{P}(X_{t+1} = x_{\nu \to 1}) &= \frac{exp(\mu)\prod_{\left\{\nu,j\right\} \in E} exp(\beta \mathbf{1}(x(j)=1))}{exp(\mu)\prod_{\left\{\nu,j\right\} \in E} exp(\beta \mathbf{1}(x(j)=1)) + exp(-\mu)\prod_{\left\{\nu,j\right\} \in E} exp(\beta \mathbf{1}(x(j)=-1))}
\\
&= \frac{exp(\beta n_{1} + \mu)}{exp(\beta n_{1} + \mu) + exp(\beta n_{-1} - \mu)}
\end{align*}
Où $n_{c}$ est le nombre de voisins de $\nu$ de label c.
Par exemple, si $\nu$ est adjacent à trois n\oe{}uds de label $1$ et un n\oe{}ud de label $-1$, alors la probabilité que $\nu$ se voit labelliser $1$ est $exp(3\beta + \mu)/(exp(3\beta + \mu)+exp(\beta - \mu))$.
Mettre ensuite en place cette méthode algorithmiquement est très simple.\\
Vérifions la réversibilité de la chaîne.
\begin{proof}
Les cas où la chaîne ne change pas d'état après un pas,(ie $X_{t} = x_{\nu \to 1}$  et $X_{t+1} = x_{\nu \to 1}$ ou $X_{t} = x_{\nu \to -1}$ et $X_{t+1} = x_{\nu \to -1}$) nous donnent immédiatement l'équation de balance détaillée, il ne reste alors qu'à traiter deux cas.
\begin{itemize}
\item Premier cas : $X_{t} = x_{\nu \to 1}$ et $X_{t+1} = x_{\nu \to -1}$.
\\

On a alors : $$ \pi(\left\{x_{\nu \to 1 } \right\}) \mathbb{P}(X_{t+1} = x_{\nu \to -1} | X_{t} = x_{\nu \to 1}) =\pi(\left\{x_{\nu \to 1 } \right\}) \frac{exp(-\mu + \beta n_{-1})}{exp(-\mu + \beta n_{-1})+exp(\mu + \beta n_{1})} $$
D'autre part : 
$$ \pi(\left\{x_{\nu \to -1 } \right\}) \mathbb{P}(X_{t+1} = x_{\nu \to 1} | X_{t} = x_{\nu \to -1}) =\pi(\left\{x_{\nu \to -1 } \right\}) \frac{exp(\mu + \beta n_{1} )}{exp( - \mu + \beta n_{-1})+exp(\mu + \beta n_{1} )} $$

On aura donc l'égalité entre ces termes si et seulement si on a :

$$ \pi(\left\{x_{\nu \to 1 } \right\})exp(-\mu + \beta n_{-1}) = \pi(\left\{x_{\nu \to -1 } \right\})exp(\mu + \beta n_{1} ) $$

Les simplifications suivantes s'opèrent dans les termes en $\pi$ : 

\begin{itemize}
\item simplification des $\frac{1}{Z}$
\item simplification des $\prod_{i \in V} exp(\mu X(i))$ sauf au n\oe{}ud $\nu$
\item simplification des $\prod_{\left\{i,j\right\} \in E} exp(\beta \mathbf{1}(x(i)=x(j))$ sauf aux arêtes ayant $\nu$ comme extrémité
\end{itemize}
~\\
On obtient alors :

$$exp(\mu + \beta n_{1} ) exp(-\mu + \beta n_{-1}) = exp(-\mu + \beta n_{-1})exp(\mu + \beta n_{1} ) $$

On a donc bien vérifié l'égalité et donc l'équation de balance détaillée.



\end{itemize}

Le deuxième cas : $X_{t} = x_{\nu \to -1}$ et $X_{t+1} = x_{\nu \to 1}$ se vérifie de la même manière.

~\\
Ayant vérifié tous les cas possibles, on obtient donc l'équation de balance détaillée qui conduit bien à la réversibilité de la chaîne.

\end{proof}

\newpage
\paragraph{\underline{\textbf{Programmation sous R}}}
~\\


\begin{lstlisting}
## X = graphe (rectangulaire ou carré), u = lancer uniforme sur [0,1], v = noeud de X ##
IsingGibbsUpdate <- function(X,u,v,beta,mu){ ## Permet de faire un pas de la chaîne de Markov associée selon le Gibbs Sampler##
  
  ##On entoure la matrice de valeurs aberrantes pour la manipuler plus facilement##
  ##On change les indices du point considéré pour se conformer à la nouvelle matrice##
  
  i = v[1] + 1
  j = v[2] + 1
  
  X = rbind(rep(0,dim(X)[2]),X)
  X = rbind(X,rep(0,dim(X)[2]))
  X = cbind(rep(0,dim(X)[1]),X)  
  X = cbind(X,rep(0,dim(X)[1]))

##Les indicatrices permettent de vérifier quelles valeurs ont les voisins du point considéré ##

  if(u< exp(mu + beta*((X[i+1,j]==1)*1 + (X[i-1,j]==1)*1 +(X[i,j+1]==1)*1 + (X[i,j-1]==1)*1))/((exp(mu + beta*((X[i+1,j]==1)*1 + (X[i-1,j]==1)*1 +(X[i,j+1]==1)*1 + (X[i,j-1]==1)*1))) + exp(-mu + beta*((X[i+1,j]==-1)*1 + (X[i-1,j]==-1)*1 +(X[i,j+1]==-1)*1 + (X[i,j-1]==-1)*1)))){
    X[i,j] =  1
  }
  else{
    X[i,j] = -1
  }
  
  ##On supprime les valeurs insérées##
  X=X[,-1]
  X=X[,-dim(X)[2]]
  X=X[-1,]
  X=X[-dim(X)[1],]
  
  X
}

\end{lstlisting}

\newpage

\begin{lstlisting}
IsingGibbssteps <- function(X,beta,mu,n){ ##effectue n pas de la chaîne de Markov pour le sampler de Gibbs, pour un graphe rectangulaire X##  

  for (i in 1:n){
  
  ##choix uniforme du noeud considéré##
    k = sample(1:dim(X)[1],1)
    l = sample(1:dim(X)[2],1)
  ##lancer uniforme sur [0,1]##
    u = runif(1)
  ##mise à jour du point##
    X=IsingGibbsUpdate(X,u,c(k,l),beta,mu)
    
  }

  X
}
\end{lstlisting}

\newpage

\begin{lstlisting}
IsingGibbsconditionnalstop <- function(X,beta,epsilon){ ##effectue un nombre aléatoire de pas de la chaîne de Markov pour le sampler de Gibbs, pour un graphe carré X##  
  
  ##On créé le vecteur Y qui contiendra les ratios de 1 pour chaque graphe##  
  Y=c(mean(X==1))
  bol = TRUE
  i=1
  
  while (bol){
	
	##Choix uniforme du noeud considéré##
    k = sample(1:dim(X)[1],1)
    l = sample(1:dim(X)[2],1)
	
	##lancer uniforme sur [0,1]##    
    u = runif(1)
    
    ##Mise à jour du noeud considéré##
    X=IsingGibbsUpdate(X,u,c(k,l),beta)
    
    ##Mise à jour du vecteur des ratios##
    Y = c(Y,mean(X==1))
    
    ##Si la ligne est décommentée, on obtient une représentation de la configuration X tout les (dim(X)[1]**2)/epsilon pas##
    ##if ((i%%((dim(X)[1]**2)/epsilon)==0)){image(X)}

	##Si on a effectué un nombre de pas suffisant, et que le nombre de 1 n'a pas varié énormément durant un certain nombre d'itérations, on s'arrête##
    if ((i>=((log(dim(X)[1]**2)*dim(X)[1]**2)/epsilon)) && ((mean(Y[i+1-floor((dim(X)[1]**(1/2))/epsilon):i])-Y[i])<epsilon)){
      break()
    }
    i=i+1
  }
  
  return(list(X,i))
  
}
\end{lstlisting}
\newpage





\subsubsection{Metropolis-Hastings}

Pour la méthode de Metropolis-Hastings, pour chaque configuration $x$ de la chaîne, on a une densité $q_{x}$. On propose ensuite un état suivant y, selon la densité $q_{x}$. L'état suivant sera donc $x$ ou $y$. La probabilité avec laquelle est choisie la configuration $y$ est donnée de telle sorte que la réversibilité s'applique. On la donne ci-dessous. Notez que, pour que cela fonctionne, il est nécessaire que si $q_{x}(y) >0$, alors $q_{y}(x) >0$ aussi. On a alors le changement vers $y$ avec probabilité : 
$$ min\left\{ 1, \frac{f_{\pi}(y)q_{y}(x)}{f_{\pi}(x)q_{x}(y)} \right\}$$

On notera aussi que $f_{\pi}$ peut-être normalisée ou non.
\\
En exemple, on considère à nouveau le modèle d'Ising. A chaque pas, on choisit un n\oe{}ud uniformément dans $V$ puis un label candidat pour ce n\oe{}ud est choisi uniformément dans $\left\{ -1,1 \right\}$. On a alors $q_{x}(y) = q_{y}(x) = 1/2$. On calcule ensuite, pour $n_{c}$ le nombre de voisins de $\nu$ de label $c$ (où c est le label proposé) et $n_{x(\nu)}$ le nombre de voisins de $\nu$ de même label que $\nu$ : 

$$\frac{f_{\pi}(y)}{f_{\pi}(x)} = \frac{exp(n_{c} \beta + c\mu)}{exp(n_{x(\nu)}\beta + x(\nu)\mu )}$$ 

L'algorithme est alors très simple à mettre en place.
D'abord, vérifions la réversibilité de la chaîne.
\begin{proof}
Les cas où la chaîne ne change pas d'état après un pas,(ie $X_{t} = x_{\nu \to 1}$  et $X_{t+1} = x_{\nu \to 1}$ ou $X_{t} = x_{\nu \to -1}$ et $X_{t+1} = x_{\nu \to -1}$) nous donnent immédiatement l'équation de balance détaillée, il ne reste alors qu'à traiter deux cas.
\begin{itemize}
\item Premier cas : $X_{t} = x_{\nu \to 1}$ et $X_{t+1} = x_{\nu \to -1}$.
\\

On a alors : $$ \pi(\left\{x_{\nu \to 1 } \right\}) \mathbb{P}(X_{t+1} = x_{\nu \to -1} | X_{t} = x_{\nu \to 1}) =\pi(\left\{x_{\nu \to 1 } \right\}) min\left\{ 1, \frac{exp(-\mu + \beta n_{-1})}{exp(\mu + \beta n_{1})} \right\} $$
D'autre part : 
$$ \pi(\left\{x_{\nu \to -1 } \right\}) \mathbb{P}(X_{t+1} = x_{\nu \to 1} | X_{t} = x_{\nu \to -1}) =\pi(\left\{x_{\nu \to -1 } \right\}) min\left\{ 1, \frac{exp(\mu + \beta n_{1})}{exp(-\mu + \beta n_{-1})} \right\} $$

On aura donc l'égalité entre ces termes si et seulement si on a :

$$ \pi(\left\{x_{\nu \to 1 } \right\}) min\left\{ 1, \frac{exp(-\mu + \beta n_{-1})}{exp(\mu + \beta n_{1})} \right\} = \pi(\left\{x_{\nu \to -1 } \right\}) min\left\{ 1, \frac{exp(\mu + \beta n_{1})}{exp(-\mu + \beta n_{-1})} \right\} $$

Les simplifications suivantes s'opèrent dans les termes en $\pi$ : 

\begin{itemize}
\item simplification des $\frac{1}{Z}$
\item simplification des $\prod_{i \in V} exp(\mu X(i))$ sauf au n\oe{}ud $\nu$
\item simplification des $\prod_{\left\{i,j\right\} \in E} exp(\beta \mathbf{1}(x(i)=x(j))$ sauf aux arêtes ayant $\nu$ comme extrémité
\end{itemize}
~\\
On obtient alors :

$$exp(\mu + \beta n_{1}) min\left\{ 1, \frac{exp(-\mu + \beta n_{-1})}{exp(\mu + \beta n_{1})} \right\} = exp(-\mu + \beta n_{-1}) min\left\{ 1, \frac{exp(\mu + \beta n_{1})}{exp(-\mu + \beta n_{-1})} \right\} $$

Par propriété du min, on obtient alors l'égalité entre les termes, qui conduit à l'équation de balance détaillée. 

\end{itemize}

~\\
Le deuxième cas : $X_{t} = x_{\nu \to -1}$ et $X_{t+1} = x_{\nu \to 1}$ se vérifie de la même manière.

~\\
Ayant vérifié tous les cas possibles, on obtient donc l'équation de balance détaillée qui conduit bien à la réversibilité de la chaîne.

\end{proof}


\newpage
\paragraph{\underline{\textbf{Programmation sous R}}}
~\\


\begin{lstlisting}
## X = graphe (rectangulaire ou carré), u = lancer uniforme sur [0,1], v = noeud de X ##

MetropolisHastingsUpdate <- function(X,u,v,beta){  ## Permet de faire un pas de la chaîne de Markov associée selon Metropolis-Hastings     
  
  ##On entoure la matrice de valeurs aberrantes pour la manipuler plus facilement##
  ##On change les indices du point considéré pour se conformer à la nouvelle matrice##
  
  i = v[1] + 1
  j = v[2] + 1
  
  X = rbind(rep(0,dim(X)[2]),X)
  X = rbind(X,rep(0,dim(X)[2]))
  X = cbind(rep(0,dim(X)[1]),X)  
  X = cbind(X,rep(0,dim(X)[1]))
  
  ##On choisit une couleur candidate pour le noeud v##
  
  c=sample(c(-1,1),1,prob=c(1/2,1/2))
  
  ##Les indicatrices permettent de vérifier quelles valeurs ont les voisins du point considéré ##
  
  if(u< exp(beta*((X[i+1,j]==c)*1 + (X[i-1,j]==c)*1 +(X[i,j+1]==c)*1 + (X[i,j-1]==c)*1))/exp(beta*((X[i+1,j]==X[i,j])*1 + (X[i-1,j]==X[i,j])*1 +(X[i,j+1]==X[i,j])*1 + (X[i,j-1]==X[i,j])*1))){
    X[i,j] =  c
  }
  
  ##On supprime les valeurs insérées##
  X=X[,-1]
  X=X[,-dim(X)[2]]
  X=X[-1,]
  X=X[-dim(X)[1],]
  
  X
} 
\end{lstlisting}

\newpage
\begin{lstlisting}
MetropolisHastingssteps <- function(X,beta,n){ ##effectue n pas de la chaîne de Markov pour Metropolis-Hastings, pour un graphe rectangulaire X##  
  
  for (i in 1:n){
  
  ##choix uniforme du noeud##
    k = sample(1:dim(X)[1],1)
    l = sample(1:dim(X)[2],1)
    
  ##lancer uniforme sur [0,1]##
    u = runif(1)
    
  ##mise à jour de la configuration X##
    X=MetropolisHastingsUpdate(X,u,c(k,l),beta)
  }
  
  X
  
}

\end{lstlisting}

\newpage
\begin{lstlisting}

MetropolisHastingsconditionnalstop <- function(X,beta,epsilon){ ##effectue un nombre aléatoire de pas de la chaîne de Markov pour Metropolis-Hastings, pour un graphe carré X## 

 ##On créé le vecteur Y qui contiendra les ratios de 1 pour chaque graphe##  
  Y=c(mean(X==1))
  bol = TRUE
  i=1
  
  
  while (bol){
  
  ##Choix uniforme du noeud considéré##
    k = sample(1:dim(X)[1],1)
    l = sample(1:dim(X)[2],1)
    
  ##lancer uniforme sur [0,1]##  
    u = runif(1)
   
  ##Mise à jour du noeud considéré##
    X=MetropolisHastingsUpdate(X,u,c(k,l),beta)
    
  ##Mise à jour du vecteur des ratios##
    Y = c(Y,mean(X==1))
    
  ##Si la ligne est décommentée, on obtient une représentation de la configuration X tout les (dim(X)[1]**2)/epsilon pas##
  ##if ((i%%((dim(X)[1]**2)/epsilon)==0)){image(X)}##
  
  ##Si on a effectué un nombre de pas suffisant, et que le nombre de 1 n'a pas varié énormément durant un certain nombre d'itérations, on s'arrête##
    if ((i>=((log(dim(X)[1]**2)*dim(X)[1]**2)/epsilon)) && ((mean(Y[i+1-floor((dim(X)[1]**(1/2)))/epsilon:i])-Y[i])<epsilon)){
      break()
    }
    i=i+1
  }
  
  return(list(X,i))
  
}


\end{lstlisting}

\newpage
\paragraph{\underline{\textbf{Discussion du critère d'arrêt dans "IsingGibbsconditionnalstop"}}}
\paragraph{\underline{\textbf{et "MetropolisHastingsconditionnalstop"}}}
~\\
\\
Le premier critère pour l'arrêt du programme est si le nombre de pas $i$ vérifie : $i>=((log(n^{2})*n^{2})/\epsilon)$, où $n^{2}$ est la taille du graphe carré considéré et $\epsilon$ est la "précision" que l'utilisateur souhaite. \\
Le terme en $n^{2}*log(n^{2})$ provient du problème du collectionneur. En effet, on souhaite, pour atteindre un certain équilibre, avoir donné la chance à chacun des n\oe{}uds d'avoir subi un changement. Cela revient à avoir sélectionné chacun des n\oe{}uds au moins une fois, ce qui revient au problème du collectionneur, où en moyenne le temps d'obtention de tous les éléments de la collection se fait en $n*log(n)$ si $n$ est la taille de la collection complète.\\
Le terme en $\epsilon$ permet de s'assurer d'avoir obtenu la visite complète de tous les n\oe{}uds, mais servira plus amplement dans l'autre condition d'arrêt présentée ci-après.\\
Le second critère est si le vecteur des ratios de $1$ vérifie :
$$|Y[i] - \frac{1}{\lfloor \frac{n}{\epsilon}\rfloor}\sum_{k=i+1-\lfloor\frac{n}{\epsilon}\rfloor}^{i}Y[k]|<\epsilon$$
C'est-à-dire, si le ratio de $1$ n'a pas évolué de plus de $\epsilon$ en moyenne depuis le temps $i+1-\lfloor\frac{n}{\epsilon}\rfloor$.
On parle donc de "précision" $\epsilon$ puisque plus cette valeur est petite, plus le temps requis pour que peu de changements s'effectuent en moyenne est grand.\\
Le terme en $n$ (où $n^{2}$ est la taille de la matrice) est ajouté pour obtenir une dépendance à la dimension dans la précision.



\subsubsection{Variables aléatoires auxiliaires / Auxiliary random variables}

Dans la plupart des applications du MCMC, la densité ciblée $X$ a une structure multiplicative. Pour ces densités, il est possible d'ajouter un vecteur $Y$ de variables aléatoires supplémentaires telles que $(X,Y)$ a une distribution jointe plus simple.
Par exemple, on considère à nouveau le modèle d'Ising avec $\mu = 0$. Pour chaque arête $\left\{ i,j \right\}$, on crée une variable aléatoire auxiliaire $Y(\left\{i,j\right\})$ telle que sa distribution conditionnée sur $X$ soit uniforme sur $[0,1]$ si $X(i) \neq X(j)$ et uniforme sur $[0,exp(\beta)]$ si on a l'égalité.\\
La densité jointe est alors uniforme sur : 
$$X \in \left\{0,1\right\}^{V} \text{et } Y \in \left\{ [0, \infty) : (\forall\left\{i,j\right\})(y\left\{i,j\right\}) \leq min(exp(\beta),1))\right\}$$
La chaîne de Markov est alors la suivante : pour $X$ donné, il suffit de choisir une nouvelle valeur de $Y$ sachant $X$, puis choisir un nouveau $X$ conditionné sur $Y$.\\
De par la construction de la chaîne, tirer $Y$ sachant $X$ est direct. Cependant, tirer $X$ sachant $Y$ est une autre histoire : prenons pour exemple le modèle d'Ising avec $\beta >0$. On a alors $exp(\beta) >1$. Lorsque $y(\left\{i,j\right\}) \in [0,1]$, alors il est possible que $x(i)=x(j)$ ou que $x(i) \neq x(j)$, mais lorsque $y(\left\{i,j\right\}) > 1$, alors on a forcément que $x(i)=x(j)$. Les arêtes avec  $y(\left\{i,j\right\}) > 1$ séparent le graphe en groupes de composants connectés tels que chacun des composants doivent avoir le même label.\\
Il suffit donc de séparer le graphe en groupes de composants connectés en se servant des arêtes $y(\left\{i,j\right\}) > 1$, puis il faut choisir un label uniformément sur $\left\{-1,1\right\}$ pour les composantes de ces groupes.\\

\subsubsection{Shift Chains}

Un autre type de chaîne utile pour les modèles répulsifs est le shift. Pour illustrer le modèle, on considère le modèle hard-core où chaque n\oe{}ud du graphe est soit occupé ($x(\nu) = 1$) soit inoccupé ($x(\nu) = 0$). Chaque n\oe{}ud occupé contribue d'un facteur $\lambda$ à la densité.\\
Dès lors qu'un des voisins de $\nu$ est occupé, la chaîne ne peut changer la valeur de $\nu$.\\
Le shift autorise un échange de label entre $\nu$ et son voisin occupé avec une certaine probabilité $p_{shift}$. Lorsque deux voisins de $\nu$ ou plus sont occupés, aucun changement n'est possible et $\nu$ reste inoccupé. 

\newpage
\section{Chapitre 2 : Procédures de rejet}

\subsection{Théorème et exemple simple}

\begin{theorem}
\end{theorem}
Soit $\nu$ une mesure finie sur un ensemble $B$ et soit $A$ un sous-ensemble de $B$ tel que $\nu(A) > 0$. Soit $X_{1},X_{2},\ldots$ des variables aléatoires iid tirées selon $\nu$ sur l'ensemble $B$. Soit enfin $T = inf \left\{t :  X_{t} \in A \right\}.$ Alors : 

$$ X_{T} \sim [ X_{1} | X_{1} \in A ]$$ 

C'est à dire, si on tire successivement des valeurs dans $B$ selon $\nu$ et que l'on rend la première valeur dans $A$, alors on le résultat provient de la mesure $\nu$ conditionnée à être dans $A$.

\begin{proof}
Cela suit du théorème fondamental de la simulation parfaite en ayant $U_{1},U_{2},\dots$ des tirages dans $B$ selon $\nu$, $b(U) = \mathbf{1}(U \in A)$,$g(U) = U$ et $f(X,U) = X$.
\end{proof}

Le nombre moyen de pas nécessaire pour obtenir un tirage dans $A$ dépend de la taille de $A$ par rapport à la taille de $B$.

\begin{theorem}
\end{theorem}
La probabilité qu'un tirage $X$ dans $B$ selon $\nu$ soit dans $A$ est $\nu(A)/\nu(B)$. Le nombre moyen de tirages nécessaires est $\nu(B)/\nu(A)$.

\begin{proof}
La première moitié du théorème découle simplement de la définition de mesure de probabilité. La seconde provient du fait que $T$ soit une loi géométrique de paramètre $\nu(A)/\nu(B)$, et donc sa moyenne est $\nu(B)/\nu(A)$.
\end{proof} 

\paragraph{Exemple : tirage uniforme sur le cercle unité}
~\\
~\\
On choisit $B = [-1,1] \times [-1,1]$ et $A = \left\{ (x,y) \in \mathbb{R}^{2} | x^{2} + y^{2} \leq 1 \right\}$.\\
L'aire de $B$ est 4 tandis que l'aire du cercle unité est $\pi$. Le nombre moyen de lancers est alors $2 * (4/\pi) = 2*1.273$, où le facteur $2$ provient du nombre d'uniformes nécessaires pour obtenir un tirage dans $B$.\\
On propose une mise en place sous R en fin de chapitre.

\subsection{Méthode de rejet pour variables aléatoires à densité}

La méthode de rejet de base n'inclut pas les variables aléatoires à densité. Cependant, celles-ci sont traitées aisément à l'aide des variables aléatoires auxiliaires. Pour cela, on considère le théorème suivant, provenant de la théorie de la mesure.

\begin{theorem}
Théorème fondamental de la simulation de Monte Carlo
\end{theorem}

Soit $X$ variable aléatoire de densité (possiblement non-normalisée) $f_{X}$ par rapport à une mesure $\nu$ sur $\Omega$. Si on a $[Y|X] \sim Unif([0,f_{X}])$, alors $(X,Y)$ est un lancer provenant de la mesure produit $\nu ~ \times$ Unif sur l'ensemble $\left\{(x,y) : x\in \Omega, 0 \leq y \leq f_{x} \right\}$.\\
~\\
Essentiellement, ce théorème nous dit que pour obtenir un lancer selon une certaine densité, il suffit de tirer selon une loi uniforme sur un espace plus grand. De plus, la densité de $X$ n'est pas forcément normalisée, ce qui sera essentiel dans les applications qui suivent. 
\\
~\\
Pour comprendre comment cela fonctionne, nous allons traiter un exemple en toute généralité, puis un exemple concret. \\
Soit $\mu$ une mesure sur un ensemble $\Omega$. On suppose que, pour une densité $g$, il est possible de générer un lancer provenant de la densité produit $\mu ~\times$ Unif sur $\Omega_{g} = \left\{ (x,y) : x \in \Omega, 0 \leq y \leq g \right\}$.\\
Une fois que ce lancer est obtenu, $X$ provient alors de la densité $g$. Mais supposons ici que le but est d'obtenir un lancer selon une densité $f$.\\
Notons d'abord que, si $(X,Y)$ est de mesure $\mu ~ \times$ Unif sur $\Omega_{g}$, alors $(X,2Y)$ est de mesure $\mu ~ \times$ Unif sur $\Omega_{2g} = \left\{ (x,y) : x \in \Omega, 0 \leq y \leq 2g \right\}$. On peut même généraliser : pour toute constante $c > 0$, $(X,cY)$ est de mesure $\mu ~ \times$ Unif sur $\Omega_{cg}$.\\
Supposons alors que $c \geq sup_{x \in \Omega} f(x)/g(x)$. Alors : 

$$ \Omega_{f} \subseteq \Omega_{cg}$$

On peut alors utiliser une méthode de rejet pour obtenir une réalisation provenant de la densité $f$. Il suffit de générer $X$ selon la densité $g$, puis de tirer uniformément $Y$ sur $[0,c*g(X)]$. Si $Y$ est aussi dans $[0,f(X)]$ (de sorte que $(X,Y) \in \Omega_{f})$ alors on accepte $(X,y)$, ce qui signifie que $X$ est un lancer selon la densité $f$. \\
Pour tester si le lancer uniforme de $[0,c*g(X)]$ est dans $[0,f(X)]$, il n'est pas nécessaire de vérifier si l'uniforme tombe effectivement dedans : on peut simplement tirer une variable aléatoire $C$ suivant une loi de Bernouilli de paramètre $f(X)/[c*g(X)]$. Si $C = 1$, on considère que $X$ est un lancer provenant de la densité $f$.\\
La probabilité d'acceptation varie inversement avec $c$, le meilleur choix possible pour $c$ est alors $sup_{x \in \Omega} f(x)/g(x)$. La valeur de $c$ n'est pas toujours évidente à calculer. Dans ce cas, une majoration suffit : l'algorithme fera simplement plus de lancers en moyenne.\\
Nous allons maintenant calculer la probabilité d'acceptation d'un lancer.

\begin{lemme}
\end{lemme}

Soit $Z_{f} = \int_{x \in \Omega} f(x) \nu(dx)$ et $Z_{g} = \int_{x \in \Omega} g(x) \nu(dx)$, les constantes de normalisation pour les densités (possiblement) non-normalisées $f$ et $g$.
Alors, pour la méthode par rejet présentée précédemment, la probabilité d'acceptation est $Z_{f}/[c*Z_{g}]$ et le nombre moyen de lancers est $c*Z_{g}/Z_{f}$.

\begin{proof}
Pour $C$, la loi de Bernouilli présentée précédemment, le problème est de calculer $\mathbb{P}(C=1)$. 

\begin{align*}
\mathbb{P}(C=1) &= \mathbb{E}[\mathbb{E}[\mathbf{1}(C=1)|X]] \\
&= \int_{x \in \Omega} \mathbb{P}(C=1|X=x)\mathbb{P}(X \in dx) \\
&= \int_{x \in \Omega} f(x)/[cg(x)](g(x)/Z_{g})\nu(dx) \\
&= [cZ_{g}]^{-1}\int_{x \in \Omega} f(x)\nu(dx) \\
&= Z_{f}/[c*Z_{g}]
\end{align*}

\end{proof}

\subsubsection{Exemple : D'une Cauchy vers une Normale}

Un exemple simple est la situation suivante : on suppose qu'un utilisateur peut générer une réalisation d'une loi de Cauchy standard de densité $g(x) = [\pi(1+x^{2})]^{-1}$. Cet utilisateur souhaite générer une réalisation d'une loi Normale standard de densité $f(x) = \frac{1}{\sqrt{2\pi}} \exp(-x^{2}/2)$.
D'abord, la normalisation n'est pas nécessaire, donc soit $g_{1}(x) = (1+x^{2})^{-1}$ et $f_{1}(x) = \exp(-x^{2}/2)$. On a que $f_{1}(x)/g_{1}(x) \leq 2 , \forall x$. On implémente alors sous R l'algorithme : 


\newpage

\paragraph{\underline{\textbf{Mise en place de la méthode de rejet sous R : d'une Cauchy vers une Normale}}}
~\\
\begin{lstlisting}
normalfromcauchy <- function(){## Fonction permettant de générer une réalisation de la loi normale standard à partir de la loi de Cauchy standard par méthode de rejet ##

##penser à changer le return pour obtenir une réalisation (return(x)) ou le temps mis à l'obtenir (return(n))##
  
  ##On initialise les valeurs ##
  C=0
  x=0
  n=0
  
  ##Tant que la bernouilli n'est pas 1##
  while(C!=1){
    
    ##On génère une Cauchy standard##
    x = rcauchy(1)
    
    ##On génère une Bernouilli du paramètre indiqué##
    C = rbinom(1,1,((sqrt(exp(1))/2)*(1+x^2)*exp(-(1/2)*x^2)))
    
    ##mise à jour du nombre de lancers##
    n=n+1
  }
  return(x)
}



##On calcule le nombre moyen de lancers nécessaires pour atteindre la sortie de l'algorithme précédent##

##On initialise le nombre moyen##
s=0

##On lance 10^6 fois l'algorithme qui retourne le nombre de lancers effectué ##
for (i in 1:10^6) {
  s=s+normalfromcauchy()
}

##On moyenne sur les 10^6 lancers
s = s/10^6



##On créé un histogramme illustrant 10^5 lancers de l'algorithme rendant une réalisation de la normale standard##

##On initialise le tableau qui contiendra les 10^5 lancers
t = matrix(0,1,10^5)

##On remplit le tableau en lançant 10^5 fois l'algorithme##
for (i in 1:10^5) {   #changer le return pour obtenir des réalisations
  t[i]=normalfromcauchy()

}

##On produit l'histogramme du tableau t et on rajoute la courbe de la densité de la loi normale standard##
hist(t,prob=T)

curve(dnorm(x, 0, 1), col="red",xlim=c(-4,4),add=T)


\end{lstlisting}

\newpage

L'histogramme rendu après un lancer du programme est le suivant : 

\includegraphics[scale=1]{graphiques/normaltocauchy.jpeg}

On obtient bien l'allure de la densité d'une loi normale standard.

On récupère aussi le nombre moyen de lancers requis afin d'obtenir une réalisation : 2.50588. On peut retrouver ce résultat de manière théorique en calculant la probabilité d'acceptation : 

\begin{align*}
\mathbb{P}(C=1) &= \int_{x \in \mathbb{R}} \mathbb{P}(X \in dx, C = 1) \\
&= \int_{x \in \mathbb{R}} g(x) \frac{1}{2}(1+x^{2})\exp(-x^{2}/2)dx \\
&= (2\pi)^{-1/2}
\end{align*}

Le nombre moyen de lancers est donc $\sqrt{2\pi} = 2.506\ldots$\\
Il est possible d'accélérer l'algorithme : on a en fait $sup_{x} (1+x^{2})\exp(-x^{2}/2) = 2/\sqrt{e}$. En remplaçant dans l'algorithme (mais aussi en calculant exactement l'intégrale), le nombre moyen de lancers devient $\sqrt{2\pi/e} = 1.520 \ldots$

\subsection{Union d'ensembles}

Une autre manière d'utiliser les méthodes de rejet est de prendre en compte les multiples manières d'obtenir une réalisation. Par exemple, on considère le problème de génération selon une mesure $\nu$ sur $S_{1} \cup \ldots \cup S_{n}$, où les ensembles $S_{i}$ sont de mesure finie $\nu(S_{i})$.\\
On considère l'algorithme suivant : on tire $I$ dans $\left\{1,2,\ldots,n\right\}$ de telle sorte que $\mathbb{P}(I=i) \propto \nu(S_{i})$. Puis, conditionnellement sur $I$, on tire $X$ dans $S_{I}$ selon la mesure $\nu$.\\
Le problème est que $X$ n'est pas tiré selon $\nu$ sur $S_{1} \cup \ldots \cup S_{n}$, car il y a plusieurs manières pour lesquelles $X$ aurait pu être choisi. Par exemple, si $X \in S_{1}$ et $X \in S_{2}$ mais $X \notin S_{3} \ldots S_{n}$, alors $I$ aurait pu être $1$ ou $2$ lors du choix de $X$.\\

\begin{lemme}
\end{lemme}
Pour l'algorithme précédent, $X$ est un tirage selon $\nu$ sur $S_{1} \cup \ldots \cup S_{n}$ avec densité $f(x) = \#\left\{i : x \in S_{i} \right\}/\nu(S_{1} \cup \ldots \cup S_{n})$

\begin{proof}
Soit $x \in S_{1} \cup \ldots \cup S_{n}$ et $C = \nu(S_{1} \cup \ldots \cup S_{n})$ Alors :

\begin{align*}
\mathbb{P}(X \in dx) &= \sum_{i=1}^{n} \mathbb{P}(X \in dx, I=i) \\
&= \sum_{i=1}^{n} \mathbb{P}(I=i)\mathbb{P}(X \in dx|I=i)\\
&= \sum_{i=1}^{n} C^{-1}\nu(S_{i}) \mathbf{1}(x \in S_{i}) \nu(dx)\nu(S_{i})^{-1}\\
&= C^{-1}\#\left\{i : x \in S_{i} \right\}
\end{align*}

\end{proof}

Par exemple, supposons que l'on veuille tirer uniformément sur les 3 cercles unités respectivement centrés en $(0,0)$,$(1/2,0)$ et $(1/2,1/2)$.\\
On tire alors $I \sim Unif(\{1,2,3\})$. Si $I=1$, on tire $X$ sur le cercle unité centré en $(0,0)$. Pour $I=2$ ou $I=3$, on tire $X$ sur le cercle centré en $(1/2,0)$ et $(1/2,1/2)$ respectivement. Après, avoir tiré $I$ puis $X$ conditionnellement à $I$, on accepte $X$ avec probabilité égale à l'inverse du nombre de cercles où se situe $X$.

\subsection{Simulation à l'aide des inégalités de Markov et Chernoff}

\subsubsection{L'inégalité de Markov en tant que procédure de rejet}

\begin{lemme}
Inégalité de Markov
\end{lemme}

On considère une variable aléatoire $X$ non-négative avec probabilité $1$ et d'espérance finie $\mathbb{E}[X]$. Alors, pour tout $a >0$ :

$$ \mathbb{P}(X \geq a) \leq \mathbb{E}[X]/a$$

Du point de vue simulation, l'inégalité de Markov nous permet de tirer depuis $[X|X \geq a]$. C'est à dire, si $X$ à pour densité $f_{X}(x)$ alors le but est de tirer depuis la densité non-normalisée $f_{X}(x)\mathbf{1}(x>a)$. Pour pouvoir appliquer une méthode de rejet, on utilise la densité non-normalisée $xf_{X}(x)$. On a alors que $f_{X}(x)\mathbf{1}(x \geq a)/[xf_{X}(x)]$ vaut $0$ lorsque $x<a$, et $1/x$ lorsque $x \geq a$. Le produit n'est donc jamais supérieur à $1/a$ ce qui permet d'utiliser la méthode de rejet suivante : 

\floatname{algorithm}{Méthode rejet Inégalité de Markov}
\begin{algorithm}
\caption{Entrées : $f$,$a$ Sortie : $X \sim f$ sachant $X > a$ }
\begin{algorithmic} 
\WHILE{$C \neq 1$}

\STATE Tirer $X$ selon la densité non-normalisée $xf(x)$
\STATE Tirer $C \sim Bern(a\mathbf{1}(X \geq a)/x)$ 

\ENDWHILE
\end{algorithmic}
\end{algorithm}

On remarque que la constante de normalisation pour la densité $xf(x)$ est simplement : $\int xf(x)\nu(dx) = \mathbb{E}[X]$. On a alors :

\begin{align*}
\mathbb{P}(C=1) &= \int_{x \geq 0} \frac{xf_{X}(x)}{\mathbb{E}[X]} \frac{a\mathbf{1}( X > a)}{x} = \int_{x \geq a} \frac{af_{X}(x)}{\mathbb{E}[X]} = \frac{a \mathbb{P}(X > a)}{\mathbb{E}[X]}\\
\end{align*}

Puisque la chance d'accepter est au plus $1$, cette fraction est aussi au plus $1$, ce qui montre l'inégalité de Markov.

\subsubsection{Les inégalités de Chernoff en tant que procédure de rejet}
Les inégalités de Chernoff donnent des limites supérieures sur la probabilité qu'un somme de variables aléatoires est supérieure (ou inférieure) à une certaine valeur. Soit $S_{n} = X_{1} + \ldots + X_{n}$, où $X_{1},\ldots,X_{n}$ sont iid; alors le but est de générer un tirage selon $S_{n}$ tel que $S_{n} \geq a$ ou $S_{n} \leq a$.\\
L'inégalité de Markov peut aussi être appliquée à une somme de variables aléatoires, mais la borne donnée n'est pas aussi précise que celle obtenue avec les inégalités de Chernoff.

\begin{lemme}
Inégalités de Chernoff
\end{lemme}
Soit une variable aléatoire $X$ telle que $\mathbb{E}[e^{tX}]$ soit finie pour $t \in [a,b]$, où $a$ est négatif et $b$ positif. Alors pour un certain $c \in \mathbb{R}$, et en notant par $mgf_{X}(t)$ la fonction génératrice des moments pour la variable aléatoire $X$, 

\begin{align*}
\mathbb{P}(X \geq c) \leq mgf_{X}(t)/\exp(tc), ~\forall t \in [0,b] \\
\mathbb{P}(X \leq c) \leq mgf_{X}(t)/\exp(tc), ~\forall t \in [a,0] 
\end{align*}

\begin{proof}
Tout d'abord : $\mathbb{P}(X \geq c) = \mathbb{P}(tX \geq tc)$ pour tout $t$ positif. De plus, $\mathbb{P}(tX \geq tc) = \mathbb{P}(\exp(tX) \geq \exp(tc))$. Enfin, on applique l'inégalité de Markov pour obtenir $\mathbb{P}(\exp(tX) \geq \exp(tc)) \leq \mathbb{E}[\exp(tX)]/\exp(tc)$. Le résultat pour l'autre inégalité est démontré de la même manière.
\end{proof}

Nous considérons à présent ce qu'il se passe lorsque l'on considère les inégalités de Chernoff pour une somme de variables aléatoires indépendante. On rappelle d'abord un résultat sur les fonctions génératrices des moments.\\

\begin{lemme}
\end{lemme}
Soit $S_{n} = X_{1} + \ldots + X_{n}$, où les$\{X_{i}\}$ sont iid de fonction génératrice des moments finie. Alors on a : $\mathbb{E}[\exp(tS_{n})] = [\mathbb{E}[\exp(tX_{i})]]^{n}$

On applique ce lemme aux inégalité de Chernoff pour obtenir : 

\begin{lemme}
\end{lemme}
Soit $S_{n} = X_{1} + \ldots + X_{n}$, où les$\{X_{i}\}$ sont iid de fonction génératrice des moments $mgf_{X_{i}}(t)$ finie pour $t \in [a,b]$, où $a$ est négatif et $b$ positif. Alors on a : 

\begin{align*}
\mathbb{P}(S_{n} \geq \alpha n) \leq  \left(\frac{mgf_{X_{i}}(t)}{\exp(t \alpha)}\right)^{n}, ~\forall t \in [0,b]\\
\mathbb{P}(S_{n} \leq \alpha n) \leq  \left(\frac{mgf_{X_{i}}(t)}{\exp(t \alpha)}\right)^{n}, ~\forall t \in [a,0]
\end{align*}

Supposons que $X_{i} \sim f_{X}$. Le but est d'utiliser la fonction génératrice des moments pour obtenir un meilleur algorithme de rejet. Pour cela, il doit être possible de générer une réalisation selon la densité $g_{t}(x) \propto e^{tx}f_{x}(x)$. Lorsque $t$ est grand, cette densité aura tendance à prendre de plus grandes valeurs. Lorsque $t$ est grand dans les négatifs, $g_{t}$ tendra à prendre des valeurs plus faibles.\\
Soit $t>0$. Pour $x \geq a$, alors $g_{t}(x) = e^{tx} f_{X}(x) \geq e^{ta}f_{X}(x)$. Alors une réalisation de $g_{t}$ peut être acceptée comme réalisation de $f_{X}$ avec probabilité $e^{ta}/e^{tx}$. Si la probabilité que $x$ soit bien plus grand que $a$ est faible, alors la probabilité d'acceptation sera très proche de $1$. Une méthode similaire s'applique lorsque $t<0$. On en déduit alors l'algorithme suivant :

\floatname{algorithm}{Méthode rejet Inégalités de Chernoff}
\begin{algorithm}[]
\caption{\newline Entrées : $f_{X}$,$a$,$t$ \newline  Sortie : $S_{n} = X_{1} + \ldots + X_{n} $sachant $S_{n} \geq a$ (lorsque $t >0$) ou sachant $S_{n} \leq a$ (lorsque $t<0$)}

\begin{algorithmic}
\STATE Si $t>0$, alors $A \leftarrow [a,\infty)$, sinon $(-\infty,a]$ 
\WHILE{$C \neq 1$}

\STATE Tirer $X_{1},\ldots,X_{n}$ iid selon la densité non-normalisée $e^{tx}f(x)$
\STATE $S_{n} \leftarrow X_{1} + \ldots + X_{n}$
\STATE Tirer $C \sim Bern(\exp(t(a-S_{n}))\mathbf{1}(S_{n}\in A))$ 

\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{lemme}
\end{lemme}
Supposons que $mgf_{X_{i}}(t)\exp(-ta/n)<1$. Alors l'algorithme précédent génère une réalisation de $[S_{n}|S_{n}>a]$ lorsque $t>0$ ou de $[S_{n}|S_{n}<a]$ lorsque $t<0$.

\begin{proof}
On considère tout vecteur $(x_{1},\ldots,x_{n})$ tel que $\sum x_{i} = s$. On considère $X_{1},\ldots,X_{n}$ iid de densité $f_{X}(x)$ et $X_{1}',\ldots,X_{n}'$ iid de densité $\exp(tx)f_{X}(x)$. Alors la densité de $S_{n}'  = X_{1}' + \ldots + X_{n}'$ est simplement la densité de $S_{n} = X_{1} + \ldots + X_{n}$ avec un facteur $\exp(tx_{1})\exp(tx_{2})\ldots\exp(tx_{n}) = \exp(ts)$.\\
On génère dans l'algorithme une variable aléatoire de densité $g(s) = \exp(ts)f_{S_{n}}(s)$ et la densité ciblée est $f(s) = f_{S_{n}}(s)\mathbf{1}(s \in A)$. On a alors $f(s)/g(s)$ qui est soit $0$ lorsque $s \notin A$ soit $\exp(-ts)$ lorsque $s \in A$.\\
Si $A = [a, \infty)$, alors $t>0$ et $\exp(-ts) \leq \exp(-ta)$. De même, lorsque $A = (-\infty, a]$, alors $t<0$  et $\exp(-ts) \leq \exp(-ta)$. On choisit donc $c = \exp(-ta)$ et on obtient $f(s)/[cg(s)] = \exp(ta)\exp(-ts)\mathbf{1}(s \in A)$ de même que dans l'algorithme. 
\end{proof}

\newpage
\paragraph{\underline{\textbf{Mise en place de la méthode de rejet sour R :}}}
\paragraph{\underline{\textbf{Inégalités de Chernoff et queue de loi binomiale}}}
~\\

\begin{lstlisting}
AR_chernoffs <- function(n,p,a){ ##fonction permettant de générer une réalisation de la loi binomiale de paramètres n et p, conditionnellement à être supérieure où égale à a en utilisant les inégalités de Chernoff##
  
  
  ##On initialise la Bernouilli##
  C=0
  
  ##On créé la valeur gamma présentée précédemment##
  gam = (a/n)*(1-p)/(p*(1-(a/n)))
  
  ##On initialise la Binomiale de paramètres n et p
  t = 0
  
  ##On initialise le nombre de lancers##
  k = 0
  
  ##Tant que la Bernouilli n'est pas 1##
  while (C != 1){
    
    ##On génère n Bernouillis de paramètres a/n## 
    t = rbinom(n,1,a/n)
    
    ##On effectue la somme pour obtenir la binomiale considérée##
    x = sum(t)
    
    ##On génère une réalisation de la Bernouilli du paramètre indiqué
    C = rbinom(1,1,(x>=a)*1*gam**(a-x))
    
    ##On met à jour le nombre de lancers effectués##
    k=k+1
  }
  
  ##On rend soit le nombre de lancers, soit la réalisation de la loi demandée (ie, k ou x))##
  return(k)
  
}


##On calcule ici le nombre moyen de lancers nécessaires pour sortir de l'algorithme précédent

s2=0
for (i in 1:10^5) {   #changer le return pour obtenir le nombre moyen de lancers nécessaires
  s2=s2 + AR_chernoffs(10,0.1,5)
}
s2 = s2/10^5
\end{lstlisting}

\newpage
\begin{lstlisting}
AR_basic <- function(n,p,a){##fonction permettant de générer une réalisation de la loi binomiale de paramètres n et p, conditionnellement à être supérieure où égale à a en utilisant la méthode de rejet basique##
  
  ##On initialise le critère d'arrêt##
  C=0
  
  ##On initialise la Binomiale de paramètres n et p##
  t = 0
  
  ##On initialise le nombre de lancers##
  k = 0
  
  ##Tant que le critère d'arrêt n'est pas 1##
  while (C != 1){
    
    ##On génère une réalisation de la Binomiale de paramètres n et p##
    t = rbinom(1,n,p)
    
    ##On met à jour le critère d'arrêt selon que la binomiale soit supérieure à a ou non##
    C = (t>=a)*1
    
    ##On met à jour le nombre de lancers##
    k=k+1
  }
  
  ##On rend soit le nombre de lancers, soit la réalisation de la loi demandée (ie, k ou t))##
  return(k)
  
}


##On calcule ici le nombre moyen de lancers nécessaires pour sortir de l'algorithme précédent
s1=0
for (i in 1:10^6) {   #changer le return pour obtenir le nombre moyen de lancers nécessaires
  s1=s1+ AR_basic(10,0.1,5)
}
s1= s1/10^6
\end{lstlisting}



\newpage
On utilise l'exemple suivant pour tester nos algorithmes : pour $n=10$ et $p=0.1$, pour $X$ la binomiale de paramètres précisés précédemment, on veut générer une réalisation de $[X|X>=5]$. \\
La méthode de base nous donne un nombre moyen de lancers de $610.9838$ tandis que la méthode à l'aide des inégalités de Chernoff nous donne un nombre moyen de lancers de $3.698136$.\\
D'où l'efficacité de cette méthode.

\subsection{Défaut des méthodes de rejet}

Le principal défaut des méthodes de rejet concerne la dimension des problèmes considérés. On prend pour exemple la génération de la variable aléatoire uniforme dans la boule de dimension $n$.\\
La méthode présentée précédemment dans le cas $n=2$ nécessite de tirer uniformément sur le carré $[-1,1] \times [-1,1]$. La probabilité d'acceptation $p$ est alors l'aire du cercle sur l'aire du carré, ie, $p = \pi /4$.\\
On peut généraliser cette méthode aux dimensions supérieures : on tire uniformément dans l'hypercube de dimension $n$ : $[-1,1]^{n}$, le but étant d'obtenir un tirage uniforme dans la boule unité de même dimension. \\
La probabilité d'acceptation est le volume de la boule sur le volume du carré soit : 

$$ p = \frac{\pi^{n/2}}{2^{n}*\Gamma(\frac{n}{2} +1)} $$

\newpage
\section{Chapitre 3}

\paragraph{Définition : Fonction de mise à jour}
~\\
\\
On dit que $\phi : \Omega \times [0,1] \to \Omega$ est une fonction de mise à jour pour une chaîne de Markov $\left\{X_{t} \right\}$ si, pour $U \sim$ Unif[0,1], $[X_{t+1}|X_{t}] \sim \phi (X_{t},U)$.
\\
La fonction $\phi$ est déterministe : tout l'aléatoire est contenu dans la variable $U$.\\
Toute chaîne qui peut-être simulée sur ordinateur est un exemple de fonction de mise à jour.\\
Une même chaîne de Markov peut-être représentée par plusieurs fonctions de mise à jour : la fonction de mise à jour n'est pas forcément unique.\\
À l'aide d'une fonction de mise à jour $\phi$, on peut représenter la trajectoire d'une chaîne de Markov $\left\{ X_{t} \right\}$. En effet, soient $U_{0},U_{1},U_{2},\ldots$ iid $\sim$ Unif([0,1]). Pour un état initial $x_{0}$, on a : $X_{1} = \phi (x_{0},U_{0})$ puis pour $i>1$, $X_{i} = \phi (X_{i-1},U_{i-1})$. \\ 
On notera alors la trajectoire jusqu'au temps t sous la forme :
$$ \phi_{t}(x_{0},U) = \phi(\phi(\phi(\ldots(\phi(x_{0},U_{0}),U_{1}),\ldots,U_{t-1}))$$
Ensuite, pour n'importe quels états $x_{0}$ et $y_{0}$ dans $\Omega$, on définit pour une fonction de mise à jour $\phi$ :  $X_{t} = \phi_{t}(x_{0},U)$ et $Y_{t} = \phi_{t}(y_{0},U)$ (en utilisant les mêmes valeurs de U). On appelle ce procédé un couplage. Notons qu'avec ce couplage, si il existe $t \geq 0$ tel que $X_{t} = Y_{t}$, alors on dit que les processus ont fusionné (ou se sont rejoints,etc).

\paragraph{Définition : Couplage}
~\\ 
\\
Soit $\mathcal{S}$ un ensemble de processus stochastiques définis sur un même ensemble $\mathcal{I}$ et un même espace d'états $\Omega$. Si il existe un indice $i \in \mathcal{I}$ et un état $x \in \Omega$ tels que pour tout $S \in \mathcal{S}$, on aie $S_{i} = x$, alors on dit que les processus stochastiques ont fusionné (ou se sont rejoints,couplés,etc). 

\paragraph{Exemple}
~\\
\\
Soit $\Omega = \left\{0,1,2\right\}$. Soit une fonction de mise à jour $\phi$ telle que :
$$ \phi(x,U) = x + \mathbf{1}(x<2,U>\frac{1}{2}) - \mathbf{1}(x>0,U \leq \frac{1}{2}).$$
Soient $\left\{X_{t}\right\}$ et $\left\{Y_{t}\right\}$ deux chaînes de Markov ayant $\phi$ comme fonction de mise à jour et telles que $X_{0} = 0$ et $Y_{0} = 2$. On suppose que $U_{0} = 0.64 , U_{1} = 0.234$ et $U_{2} = 0.1 $. On a donc les trajectoires suivantes : $(X_{0},X_{1},X_{2},X_{3}) = (0,1,0,0)$ et $(Y_{0},Y_{1},Y_{2},Y_{3}) = (2,2,1,0)$.\\
Les deux chaînes ont donc fusionné au temps $t=3$.

\paragraph{Théorème CFTP (Coupling From The Past)}
~\\
\\
On suppose que $\phi$ est une fonction de mise à jour pour une chaîne de Markov définie sur $\Omega$, telle que pour $U = (U_{0},U_{-1},\ldots,U_{-t-1}) \sim$ Unif($[0,1]^{t}$) on ait :\\
\begin{itemize}
\item Pour $Y \sim \pi, \phi (Y,U_{0}) \sim \pi$
\item Il existe un ensemble $A \subseteq [0,1]^{t}$ tel que $\mathbb{P}(U \in A) > 0$ et $\phi_{t}(\Omega,A) = \left\{ x \right\}$ pour un certain $x \in \Omega$
\end{itemize}
Posons alors, pour tout $x \in \Omega$,

\begin{align*}
Y_{0} = \phi_{t}(x_{0},U_{0})\mathbf{1}(U_{0} \in A) + \phi_{t}(\phi_{t}(x_{0},U_{-1}),U_{0})\mathbf{1}(U_{-1} \in A) 
&+ \\ \phi_{t}(\phi_{t}(\phi_{t}(x_{0},U_{-2}),U_{-1}),U_{0})\mathbf{1}(U_{-2} \in A) + \ldots 
\end{align*}
 

Alors $Y_{0} \sim \pi$.

\paragraph{\underline{\textit{Preuve}}}
~\\
\\
Soit $x_{0} \in \Omega$. Le résultat est immédiat en utilisant le théorème fondamental de la simulation parfaite, en posant $g(U) = \phi_{t}(x_{0},U)$,$b(U) = \mathbf{1}(U \in A)$, et $f(X,U) = \phi_{t}(X,U)$.
\end{document}